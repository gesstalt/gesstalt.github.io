<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
	<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
	<meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<title>
	Research work on Industry 4.0
	</title>
    <script src="tabcontent.js" type="text/javascript"></script>
    <link href="template2/tabcontent.css" rel="stylesheet" type="text/css" />
<style type="text/css">
<!--
.style1 {
	font-family: Arial, Helvetica, sans-serif;
	font-size: medium;
	font-weight: bold;
}
.style3 {
	font-family: Arial, Helvetica, sans-serif;
	color: #990000;
	font-weight: bold;
}
.style4 {font-family: Arial, Helvetica, sans-serif; font-size: larger; font-weight: bold; color:#990000; }

li:not(:last-child) {
    margin-bottom: 15px;
}
-->
</style>
</head>
<body style="background:#F6F9FC; font-family:Arial;">
<div align="right" style="position:relative"> Click <a href="../index.html">here</a> to go to the home page</div>
<h1 align="center"> Research work on Industry 4.0</h1>
<hr color="tomato">
<br>
<!-- Begining of slider div -->
	
	<div id="carouselExampleIndicators" class="carousel slide" data-ride="carousel">
  		<ol class="carousel-indicators">
    			<li data-target="#carouselExampleIndicators" data-slide-to="0" class="active"></li>
			<li data-target="#carouselExampleIndicators" data-slide-to="1"></li>
  		</ol>
  		<div class="carousel-inner">
			   <div class="carousel-item active">
      				<img class="d-block w-100" src="../images/Joy-Website-Slider-I40-1.png" alt="First slide">
    			   </div>
			<div class="carousel-item">
      				<img class="d-block w-100" src="../images/Joy-Website-Slider-I40-2.png" alt="Second slide">
    			   </div>
  		</div> <!-- End of inner-->
  		<a class="carousel-control-prev" href="#carouselExampleIndicators" role="button" data-slide="prev">
    			<span class="carousel-control-prev-icon" aria-hidden="true"></span>
    			<span class="sr-only">Previous</span>
  		</a>
  		<a class="carousel-control-next" href="#carouselExampleIndicators" role="button" data-slide="next">
    			<span class="carousel-control-next-icon" aria-hidden="true"></span>
    			<span class="sr-only">Next</span>
  		</a>
	</div> 
<!-- End of slider div -->
	<div class="jumbotron">
	<div class="row">
  		<div class="col col-lg-2">
			<img src="../images/I4_XAI.png" alt="..." class="img-thumbnail" width="200" height="200">
		</div>
  		<div class="col">
			<h4>
				From Pixels to Insight: An ExplainableAI Inspried Approach
			</h4>
			<p>
				Abstract: 
				In this study, an automated detection methodology is employed to handle large volumes of image data using the Neu database of 1440 grayscale images across six defect classes. Texture features are extracted via Gray-Level Co-Occurrence Matrix (GLCM) analysis, and these features are fed into a Random Forest Classifier, achieving an overall test accuracy of 89%. SHAP plots are utilized to interpret the model's outputs, providing clear visual explanations of the complex Random Forest model.
				<hr>
				<a class="btn btn-primary btn-sm" href="https://link.springer.com/chapter/10.1007/978-981-97-3242-5_20" role="button">
					Conference Paper
				</a>
			</p>
		</div>
	</div>
	<div class="row">
  		<div class="col col-lg-2">
			<img src="../images/iot-4.avif" alt="..." class="img-thumbnail" width="200" height="200">
		</div>
  		<div class="col">
			<h4>
				A Fast Defect Recognition and Localization Network (FDRLNet) for Steel Surfaces
			</h4>
			<p>
				Abstract: 
				This research introduces Fast Defect Recognition and Localization Network (FDRLNet) to correctly identify and localise surface flaws in steel manufacturing units. 
				Vision-based systems and camera pictures categorise and pinpoint surface faults for automated industrial inspection and quality control. 
				The publicly accessible Northeastern University (NEU-DET) surface defect dataset validates the suggested technique, which has strong prediction abilities at greater inference rates than existing competitor approaches. 
				The research proposes real-time manufacturing fault identification technique.
				<hr>
				<a class="btn btn-primary btn-sm" href="##" role="button">
					Journal Paper
				</a>
			</p>
		</div>
	</div>
	<div class="row">
  		<div class="col col-lg-2">
			<img src="../images/iot-3.avif" alt="..." class="img-thumbnail" width="200" height="200">
		</div>
  		<div class="col">
			<h4>
				An Improved Deep Learning Model for Steel Surface Defect Classification
			</h4>
			<p>
				Abstract: Manufacturing industries contemplate integrating computer vision and artificial intelligence into shop floor operations, such as steel surface defect identification, to realize smart manufacturing goals. 
				However, inadequate annotated training datasets and reduced prediction abilities with image perturbations restrict the practical implementation. 
				This paper introduces NSLNet framework utilizing ImageNet as a feature-extractor combined with adversarial training in the extracted feature space through Neural Structure Learning to address these barriers. 
				The experiments on public (NEU) and synthetically generated datasets (ENEU) showed that the NSLNet could learn with few training samples maintaining resilience against image perturbations outperforming conventional models significantly and nearest deep learning competitors marginally.
			<hr>
				<a class="btn btn-primary btn-sm" href="https://doi.org/10.1016/j.mfglet.2022.10.001" role="button">
					Journal Paper
				</a>
			</p>
		</div>
	</div>
	<div class="row">
  		<div class="col col-lg-2">
			<img src="../images/iot-2.avif" alt="..." class="img-thumbnail" width="200" height="200">
		</div>
  		<div class="col">
			<h4>
				On Enhancing Prediction Abilities of Vision-based Metallic Surface Defect Classification
			</h4>
			<p>
				Abstract: This paper provides a robust vision-based Surface Defect Classification system for automated industrial inspection using Histogram Equalization and Neural Structure Learning (NSL) with adversarial training. 
				A new deep neural network architecture generates adversarial samples in the extracted feature space and is assessed using a frequently used steel surface defect dataset (NEU) and the Extended Diversity Enhanced (ENEU) dataset replicating shop floor circumstances. 
				The proposed strategy outperforms ENEU and deep learning rivals by improving recognition accuracy from 87.7% to 92.4%. 
				Adversarial training improves machine learning model generalisation.
			<hr>
				<a class="btn btn-primary btn-sm" href="https://doi.org/10.1016/j.engappai.2022.105553" role="button">
					Journal Paper
				</a>
			</p>
		</div>
	</div>
	<div class="row">
  		<div class="col col-lg-2">
			<img src="../images/iot-1.avif" alt="..." class="img-thumbnail" width="200" height="200">
		</div>
  		<div class="col">
			<h4>Steel Surface Defect Classification using Deep Learning</h4>
			<p>
				Abstract: Surface defect recognition of products is a necessary process to guarantee the quality of industrial production. This paper proposes a  hybrid model, S2D2Net (Steel Surface Defect Diagnosis Network), for an efficient and robust inspection of the steel surface during the manufacturing process. 
				The S2D2Net uses a pretrained ImageNet model as a feature extractor and learns a Capsule Network over the extracted features. 
				The experimental results on a publicly available steel surface defect dataset (NEU) show that S2D2Net achieved <strong>99.17%</strong> accuracy 
				with minimal training data and improved by <strong>9.59%</strong> over its closest competitor based on GAN. S2D2Net proved its robustness by achieving <strong>94.7%</strong> accuracy on a diversity enhanced dataset, ENEU, 
				and improved by <strong>3.6%</strong> over its closest competitor. Our approach has better, and robust recognition performance compared to other state-of-the-art DNN-based detectors.
				<hr>
				<a class="btn btn-primary btn-sm" href="https://ieeexplore.ieee.org/abstract/document/9506405" role="button">
					Conference Paper
				</a>
			</p>
		</div>
	</div>
	
</div>

<!--
<ol>
    <li>
        <strong>
            Lungs Compliance Meter using Ultrasonic Sensors
        </strong>
       [Along with Dr. Sabyasachi Sircar, AIIMS Jodhpur]
        <br><br>
        Abstract:  <i>Lungs Compliance Meter is a simple automated device to demonstrate the measure of volume/pressure change in 
            human lungs using the compliance curve. It is working model for teaching <strong>Dynamic Airway Compression</strong>.</i>
        <br><br>
        Click <a href="http://www.vslcreations.in/lcm/">here</a> to go to the project page
        <br>
    </li>
    <li>
        <strong>
            Room Occupancy Counting Using Video Processing 
        </strong>
        [Along with <a href="http://home.iitj.ac.in/~ramana/">Venkata Ramana Badarla</a>]
        <br><br>
        Abstract:  <i>The purpose of the report is to examine the usage of Computer Vision techniques for dealing with 2 kinds of events:
            <ol>
                <li>Detection of opening of a particular door in a room.</li>
                <li>Prediction of the direction of movement (entry or exit).</li>
            </ol>
        </i>
        <br>
        Click <a href="">here</a> to go to the project page
    </li>
</ol>
-->
</body>
</html>
