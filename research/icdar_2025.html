<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>From Notes to Keys: A VR Learning Environment for Sheet Music Interpretation</title>
    <style>
        :root {
            --flameb: #182361;
            --flamey: #ff9d00;
            --flameyl: #ffde59;
            --myblue: #004682;
        }
        
        body {
            font-family: 'Arial', sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        
        header {
            background-color: var(--flameb);
            color: white;
            padding: 30px 0;
            text-align: center;
            margin-bottom: 30px;
            border-bottom: 8px solid var(--flamey);
        }
        
        h1 {
            font-size: 3rem;
            margin-bottom: 10px;
            color: var(--flameb);
        }
        
        h2 {
            font-size: 2.2rem;
            color: var(--flamey);
            margin-top: 40px;
            border-bottom: 2px solid var(--flamey);
            padding-bottom: 10px;
        }
        
        h3 {
            font-size: 1.8rem;
            color: var(--myblue);
        }
        
        .authors {
            font-size: 1.3rem;
            margin: 20px 0;
        }
        
        .affiliations {
            font-size: 1rem;
            margin-bottom: 30px;
        }
        
        .container {
            display: flex;
            flex-wrap: wrap;
            gap: 30px;
        }
        
        .section {
            background: white;
            border: 2px solid var(--myblue);
            border-radius: 10px;
            padding: 25px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
            flex: 1 1 30%;
            min-width: 300px;
        }
        
        .section-title {
            background-color: var(--flameb);
            color: white;
            padding: 15px;
            margin: -25px -25px 20px -25px;
            border-radius: 8px 8px 0 0;
            font-size: 1.5rem;
            font-weight: bold;
        }
        
        ul {
            padding-left: 20px;
        }
        
        li {
            margin-bottom: 10px;
        }
        
        .full-width {
            flex: 1 1 100%;
        }
        
        .logos {
            display: flex;
            justify-content: center;
            flex-wrap: wrap;
            gap: 20px;
            margin: 30px 0;
        }
        
        .logos img {
            height: 80px;
            margin: 0 15px;
        }
        
        .poster-image {
            width: 100%;
            max-width: 800px;
            display: block;
            margin: 30px auto;
            border: 1px solid #ddd;
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
        }
        
        .results-grid {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 20px;
            margin-top: 20px;
        }
        
        .result-item {
            text-align: center;
        }
        
        .result-item img {
            width: 100%;
            border: 1px solid #ddd;
            border-radius: 5px;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: center;
        }
        
        th {
            background-color: var(--flameb);
            color: white;
        }
        
        tr:nth-child(even) {
            background-color: #f2f2f2;
        }

        .algorithm-box {
    background-color: #f8f9fa;
    border: 1px solid #dee2e6;
    border-radius: 5px;
    padding: 20px;
    margin-top: 20px;
    font-family: 'Courier New', monospace;
}

.algorithm-box h3 {
    color: var(--flameb);
    border-bottom: 2px solid var(--flamey);
    padding-bottom: 8px;
    margin-top: 0;
}

.algorithm-steps {
    counter-reset: step;
    padding-left: 0;
}

.algorithm-steps > li {
    list-style: none;
    position: relative;
    padding-left: 2em;
    margin-bottom: 15px;
    line-height: 1.5;
}

.algorithm-steps > li:before {
    counter-increment: step;
    content: counter(step) ".";
    position: absolute;
    left: 0;
    font-weight: bold;
    color: var(--flameb);
}

.algorithm-steps ul {
    padding-left: 1.5em;
    margin-top: 8px;
}

.algorithm-steps ul li {
    list-style-type: disc;
    margin-bottom: 5px;
}
        
        @media (max-width: 768px) {
            .results-grid {
                grid-template-columns: 1fr;
            }
            
            .section {
                flex: 1 1 100%;
            }
            
            h1 {
                font-size: 2rem;
            }
            
            h2 {
                font-size: 1.8rem;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="logos">
            <img src="FLAME-University-Logo.webp" alt="FLAME University">
            <img src="iitj_logo.png" alt="IIT Jodhpur">
            <img src="rkm_logo.png" alt="RKM">
            <img src="monash_logo.png" alt="Monash University">
        </div>
        <h1>From Notes to Keys</h1>
        <h2>A VR Learning Environment for Sheet Music Interpretation</h2>
        <div class="authors">
            Sandeep Khanna<sup>1,3</sup>, 
            Atanu Saha<sup>2,3</sup>, 
            Rahul Kumar Ray<sup>3</sup>, 
            Rakesh Patibanda<sup>4</sup>, 
            Chiranjoy Chattopadhyay<sup>3</sup>
        </div>
        <div class="affiliations">
            <sup>1</sup>Indian Institute of Technology Jodhpur, Jodhpur, India &nbsp; ‚Ä¢ &nbsp;
            <sup>2</sup>Ramakrishna Mission Vivekananda Educational and Research Institute, Belur, India &nbsp; ‚Ä¢ &nbsp;
            <sup>3</sup>FLAME University, Pune, India &nbsp; ‚Ä¢ &nbsp;
            <sup>4</sup>Monash University, Australia
        </div>
        <p>International Conference on Document Analysis and Recognition. September 16-21, 2025. Wuhan, Hubei, China.</p>
    </header>
    
    <div class="container">
        <div class="section">
            <div class="section-title">Summary</div>
            <ul>
                <li><strong>Motivation:</strong> Learning to interpret sheet music and play piano is challenging for beginners due to the lack of real-time feedback and cognitive demands.</li>
                <li><strong>Problem:</strong> Existing platforms do not offer seamless sheet music recognition or intuitive guidance.</li>
                <li><strong>Proposed Solution:</strong> We present a novel system that integrates Optical Music Recognition (OMR) and Virtual Reality (VR).</li>
                <li><strong>Technical Innovation:</strong>
                    <ul>
                        <li><strong>OMR Module:</strong> Enhances note detection with scale and rotation invariance.</li>
                        <li><strong>VR Guidance:</strong> Maps detected musical notes to corresponding piano keys.</li>
                    </ul>
                </li>
            </ul>
        </div>
        
        <div class="section">
            <div class="section-title">OMR Architecture</div>
            <img src="omr_architecture.png" style="width:100%; margin-bottom:15px;">
            <p>Unified framework for music sheet segmentation: pre-processing (rotation correction, enhancement), U-Net-based staff and symbol segmentation.</p>
        </div>
        
        <div class="section">
    <div class="section-title">System Schematic</div>
    <img src="scheme_image.png" alt="System Schematic" style="width:100%; margin-bottom:15px;">
    <p>Schematic of the system: OMR converts sheet music to MusicXML, which drives key highlighting in a Unity VR piano for real-time, interactive learning with Meta Quest 3.</p>
    
    <div class="algorithm-box">
        <h3>MusicXML Generation Algorithm</h3>
        <ol class="algorithm-steps">
            <li><strong>Input:</strong> Musical symbols ùíÆ = {s·µ¢ = (t·µ¢, x·µ¢, œÑ·µ¢, d·µ¢, ùíú·µ¢)}</li>
            <li><strong>Phase I: Symbol Processing</strong>
                <ul>
                    <li>Sort ùíÆ by track t·µ¢ and position x·µ¢</li>
                    <li>Partition into tracks ùíØ‚Çñ for k ‚àà {1..m}</li>
                </ul>
            </li>
            <li><strong>Phase II: Temporal Quantization</strong>
                <ul>
                    <li>Apply quantization ùí¨ to positions x·µ¢</li>
                    <li>Set time signature œÉ = (n, 2·µñ)</li>
                    <li>Compute measure duration Œº = (n¬∑4)/2·µñ</li>
                </ul>
            </li>
            <li><strong>Phase III: Alignment</strong>
                <ul>
                    <li>Build alignment graph ùí¢_B between positions and symbols</li>
                    <li>Compute maximum matching ‚Ñ≥</li>
                </ul>
            </li>
            <li><strong>Phase IV: Measure Filling</strong>
                <ul>
                    <li>For each measure l and track k:</li>
                    <li>Add rests where ‚àëd·µ¢ < Œº</li>
                </ul>
            </li>
            <li><strong>Phase V: XML Generation</strong>
                <ul>
                    <li>Transform symbols to XML elements ùíØ_XML</li>
                    <li>Structure document ùí≥ = (ùí≥_head, ùí≥_part)</li>
                </ul>
            </li>
            <li><strong>Return</strong> MusicXML ùí≥</li>
        </ol>
    </div>
</div>
        
        <div class="section">
            <div class="section-title">Contributions</div>
            <ul>
                <li><strong>Methodological:</strong> Proposed a scale- and rotation-invariant OMR with a structured pipeline linking OMR outputs to real-time VR.</li>
                <li><strong>Artifact:</strong> Developed a prototype converting sheet music into an interactive VR piano in real-time.</li>
                <li><strong>Empirical:</strong> Evaluate the impact of the OMR-VR system on engagement and skill acquisition.</li>
            </ul>
        </div>
        
        <div class="section">
            <div class="section-title">VR Guidance</div>
            <img src="piano_vr_key.png" alt="VR Piano" style="width:100%; margin-bottom:15px;">
            <ul>
                <li><strong>OMR to MusicXML:</strong> Sheet music converted using OMR into MusicXML.</li>
                <li><strong>Unity 3D VR Piano:</strong> Realistic virtual piano with interactive keys.</li>
                <li><strong>Key Highlighting:</strong> Keys dynamically highlighted based on MusicXML.</li>
                <li><strong>Hand Tracking:</strong> Users play highlighted keys using virtual tracked hands.</li>
                <li><strong>Spatial Audio:</strong> Piano sounds play in the key location.</li>
            </ul>
        </div>
        
        <div class="section full-width">
            <div class="section-title">Experimental Results</div>
            
            <h3>Rotation Invariance</h3>
            <div class="results-grid">
                <div class="result-item">
                    <img src="https://via.placeholder.com/300x200?text=Rotated+Image" alt="Rotated Image">
                    <p>Left: Rotated image</p>
                </div>
                <div class="result-item">
                    <img src="https://via.placeholder.com/300x200?text=After+Correction" alt="After Correction">
                    <p>Middle: After correction</p>
                </div>
                <div class="result-item">
                    <img src="https://via.placeholder.com/300x200?text=OMR+Output" alt="OMR Output">
                    <p>Right: OMR output</p>
                </div>
            </div>
            
            <h3>Scale Invariance</h3>
            <div class="results-grid">
                <div class="result-item">
                    <img src="https://via.placeholder.com/300x200?text=Blurred+Input" alt="Blurred Input">
                    <p>Left: Blurred input</p>
                </div>
                <div class="result-item">
                    <img src="https://via.placeholder.com/300x200?text=Enhanced" alt="Enhanced">
                    <p>Middle: Real-ESRGAN enhanced</p>
                </div>
                <div class="result-item">
                    <img src="https://via.placeholder.com/300x200?text=Segmentation" alt="Segmentation">
                    <p>Right: Segmentation via U-Nets</p>
                </div>
            </div>
            
            <h3>Quantitative Results</h3>
            <table>
                <thead>
                    <tr>
                        <th colspan="3">First Set</th>
                        <th colspan="3">Second Set</th>
                    </tr>
                    <tr>
                        <th>Blur</th>
                        <th>OEMER</th>
                        <th>Ours</th>
                        <th>Blur</th>
                        <th>OEMER</th>
                        <th>Ours</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>13</td>
                        <td>0.91</td>
                        <td><strong>0.96</strong></td>
                        <td>27</td>
                        <td>0.74</td>
                        <td><strong>0.89</strong></td>
                    </tr>
                    <tr>
                        <td>15</td>
                        <td>0.89</td>
                        <td><strong>0.95</strong></td>
                        <td>29</td>
                        <td>0.71</td>
                        <td><strong>0.88</strong></td>
                    </tr>
                    <tr>
                        <td>17</td>
                        <td>0.87</td>
                        <td><strong>0.94</strong></td>
                        <td>31</td>
                        <td><em>ND</em></td>
                        <td><strong>0.62</strong></td>
                    </tr>
                    <tr>
                        <td>19</td>
                        <td>0.84</td>
                        <td><strong>0.94</strong></td>
                        <td>33</td>
                        <td><em>ND</em></td>
                        <td><strong>0.50</strong></td>
                    </tr>
                </tbody>
            </table>
            <p>IoU scores for segmentation (OEMER vs Ours) under varying blur (DeepScoresV2).</p>
        </div>
    </div>
    
    <footer style="margin-top: 50px; text-align: center; padding: 20px; background-color: #f5f5f5;">
        <p>For more information, please contact the authors. </p>
        <p>¬© 2025 FLAME University. All rights reserved.</p>
    </footer>
</body>
</html>
